#read csv
Credit_dat <- read.csv("creditcard.csv")

#structure of the data
str(Credit_dat)

#convert class to a factor variable
Credit_dat$Class <- factor(Credit_dat$Class, levels = c(0,1))

#Summary
summary(Credit_dat)

#count the missing values
sum(is.na(Credit_dat))

#get the distribution of fraud and legit transactions
table(Credit_dat$Class)

#find the percentage of fraud and legit transactions in the dataset
prop.table(table(Credit_dat$Class))

#pie chart of credit card transaction 
labels <- as.numeric(as.character(c("legit","fraud") ))
labels <- c("legit","fraud")
labels <- paste(labels, round(100*prop.table(table(Credit_dat$Class))), 2)
labels <- paste0(labels,"%")

pie(table(Credit_dat$Class),labels, col = c("orange", "yellow"),
    main = "pie chart of credit card transaction")

#no model prediction

predictions <- rep.int(0, nrow(Credit_dat))
predictions <- factor(predictions, levels = c(0,1))

install.packages('caret')
library(caret)
install.packages("e1071")
library(e1071)
confusionMatrix(data = predictions, reference = Credit_dat$Class)

library(dplyr)
set.seed(1)
Credit_dat <- Credit_dat %>% sample_frac(0.1)

table(Credit_dat$Class)

library(ggplot2)

ggplot(data = Credit_dat, aes(x = V1, y = V2, col = Class)) +
  geom_point() +
  theme_bw() +
  scale_color_manual(values = c('dodgerblue2','red'))

#creating training and test sets for fraud detection model
install.packages('caTools')
library(caTools)

set.seed(123)

data_sample = sample.split(Credit_dat$Class,SplitRatio = 0.80)

train_data = subset(Credit_dat,data_sample==TRUE)

test_data = subset(Credit_dat,data_sample==FALSE)

dim(train_data)
dim(test_data)

#Random Over-Sampling(ROS)

table(train_data$Class)

n_legit <- 22747
new_frac_legit <- 0.50
new_n_total <- n_legit/new_frac_legit
new_n_total

install.packages('ROSE')
library(ROSE)
oversampling_result <- ovun.sample(Class ~ .,
                                   data = train_data,
                                   method = "over",
                                   N = new_n_total,
                                   seed = 2019)
oversampled_credit <- oversampling_result$data

table(oversampled_credit$Class)

ggplot(data = oversampled_credit, aes(x = V1, y = V2, col = Class))+
  geom_point(position = position_jitter(width = 0.1))+
  theme_bw()+
  scale_color_manual(values = c('dodgerblue2','red'))

#random under sampling(RUS)

table(train_data$Class)

n_fraud <- 38
new_frac_fraud <- 0.50
new_n_total <- n_fraud/new_frac_fraud

undersampling_result <- ovun.sample(Class ~ .,
                                    data = train_data,
                                    method ="under",
                                    N = new_n_total,
                                    seed = 2019)
undersampled_credit <- undersampling_result$data
 table(undersampled_credit$Class)

 ggplot(data = undersampled_credit, aes(x = V1, y = V2, col = Class))+
   geom_point(position = position_jitter(width = 0.1))+
   theme_bw()+
   scale_color_manual(values = c('dodgerblue2','red'))

 #ROS AND RUS
 
 n_new <- nrow(train_data)
 fraction_fraud_new <- 0.50

 sampling_result <- ovun.sample(Class ~ .,
                                data = train_data,
                                method = "both",
                                N = n_new,
                                p = fraction_fraud_new,
                                seed = 2019) 
sampled_credit <- sampling_result$data 

as.numeric(table(sampled_credit$Class))
prop.table(as.numeric(table(sampled_credit$Class)))

ggplot(data = sampled_credit, aes(x = V1, y = V2, col = Class))+
  geom_point(position = position_jitter(width = 0.2))+
  theme_bw()+
  scale_color_manual(values = c('dodgerblue2','red'))

#using SMOTE to balance the dataset

install.packages("smotefamily")
library(smotefamily)

table(train_data$Class)

#set the number of fraud and legitimate cases, and the desired percentage of legitimate cases
n0 <- 22747
n1 <- 38
r0 <- 0.6

#calculate the vaule for the dup_size parameter of SMOTE
ntimes <- ((1-r0)/r0) * (n0/n1) - 1

smote_output = SMOTE(X = train_data[ , -c(1,31)],
                     target = train_data$Class,
                     K = 5,
                     dup_size = ntimes)
credit_smote <- smote_output$data
colnames(credit_smote)[30] <- "Class"

prop.table(table(credit_smote$Class))

#class distribution for original dataset
ggplot(train_data, aes(x = V1, y = V2, color = Class)) +
  geom_point()+
  scale_color_manual(values = c('dodgerblue2','red'))

#Class distribution for smote  
ggplot(credit_smote, aes(x = V1, y = V2, color = Class)) +
  geom_point()+
  scale_color_manual(values = c('dodgerblue2','red'))

install.packages('rpart')
install.packages('rpart.plot')
library(rpart)
library(rpart.plot)

CART_model <- rpart(Class ~ .,credit_smote)

rpart.plot(CART_model, extra = 0, type = 5, tweak = 1.2)

#predict farud classes
predicted_val <- predict(CART_model, test_data, type = 'class')

#Build Confusion Matrix

library(caret)
confusionMatrix(predicted_val, test_data$Class)

#Decision tree without SMOTE
CART_model <- rpart(Class ~ .,train_data[,-1])

rpart.plot(CART_model, extra = 0, type = 5, tweak = 1.2)

#predict farud classes
predicted_val <- predict(CART_model, test_data[,-1], type = 'class')

#Build Confusion Matrix

library(caret)
confusionMatrix(predicted_val, test_data$Class)


predicted_val <- predict(CART_model, Credit_dat[,-1], type = 'class')
confusionMatrix(predicted_val, Credit_dat$Class)
